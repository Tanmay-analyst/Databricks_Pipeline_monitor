# Databricks Pipeline Monitoring & 30-Day Trend Report

## üìã Overview

This solution provides comprehensive monitoring and reporting for Databricks pipeline jobs, including:

1. **Real-time Job Monitoring** - Monitors Databricks jobs and performs root cause analysis on failures
2. **30-Day Trend Report** - Executive-friendly Excel workbook with metrics, visualizations, and KPIs
3. **Automated GitHub Integration** - All reports and artifacts are automatically pushed to GitHub

## üîç Monitoring Results

### Job Status Summary

**Job Name:** Job1  
**Status:** ‚ùå FAILED  
**Failure Time:** 2026-02-10 16:01:52 UTC  
**Execution Duration:** 0.00 minutes  

### Root Cause Analysis

**Failure Category:** Infrastructure or performance-related  
**Error Type:** Multi-Task Job Failure  
**Total Tasks:** 2  
**Failed Tasks:** Job1, Job1  

**Run Details:** [View in Databricks UI](https://dbc-e120af00-28ff.cloud.databricks.com/?o=7474645529419140#job/247667064659313/run/307371849478540)

### Failure Pattern Analysis

‚ö†Ô∏è **CRITICAL ALERT: RECURRING FAILURE DETECTED**

- Recent runs analyzed: 5
- Failed: 5 | Success: 0
- Run history: FAILED ‚Üí FAILED ‚Üí FAILED ‚Üí FAILED ‚Üí FAILED
- **This indicates a systemic issue requiring urgent attention!**

### Recommended Actions

1. Check the Databricks UI run page for detailed logs
2. Review notebook execution output
3. Examine cluster event logs
4. Check driver logs (Spark UI)
5. Review stderr/stdout outputs
6. Investigate infrastructure issues:
   - Insufficient memory
   - Cluster failures
   - Timeouts
   - Resource limits

## üìä Excel Workbook: Pipeline_30Day_Trend_Report

### How to Generate the Report

1. **Prerequisites:**
   ```bash
   pip install pandas numpy openpyxl
   ```

2. **Run the script:**
   ```bash
   python generate_pipeline_report.py
   ```

3. **Output:**
   - File: `Pipeline_30Day_Trend_Report.xlsx`
   - Contains 5 sheets with comprehensive analysis

### Workbook Structure

#### 1. **Data Sheet**
   - **Table Name:** tblData
   - **Columns:**
     - Date (date only)
     - PipelineID (text)
     - PipelineName (text)
     - Owner (text)
     - System (text) - e.g., Databricks, DataFactory, Synapse
     - JobType (text) - e.g., Ingestion, Transformation, ETL, ML, Export
     - Status (text: "Success" or "Failed")
     - DurationSec (number)
     - StartTime (datetime)
     - EndTime (datetime)
     - ErrorCode (text; empty for successes)
   - **Features:**
     - Formatted as Excel table for easy filtering and sorting
     - Auto-adjusting formulas in other sheets
     - Sample data for last 30 days (replace with actual Databricks data)

#### 2. **Metrics Sheet**
   - **Daily Aggregates:**
     - Date
     - TotalJobs
     - Successes
     - Failures
     - AvgDurationSec
     - P95DurationSec (95th percentile)
     - SuccessRate
   - **Formulas (using structured references):**
     ```excel
     TotalJobs: =COUNTIF(tblData[Date], A2)
     Successes: =COUNTIFS(tblData[Date], A2, tblData[Status], "Success")
     Failures: =COUNTIFS(tblData[Date], A2, tblData[Status], "Failed")
     AvgDurationSec: =IFERROR(AVERAGEIFS(tblData[DurationSec], tblData[Date], A2), 0)
     P95DurationSec: =IFERROR(PERCENTILE.INC(IF(tblData[Date]=A2, tblData[DurationSec]), 0.95), 0)
     SuccessRate: =IFERROR(C2/B2, 0)
     ```
   - **Conditional Formatting:**
     - Red highlight for failures exceeding threshold
     - Red highlight for success rate below threshold
     - Red highlight for P95 duration exceeding threshold

#### 3. **Config Sheet**
   - **Thresholds:**
     - FailureThreshold = 5 (alert if daily failures exceed this)
     - SuccessRateThreshold = 0.95 (alert if success rate falls below 95%)
     - P95DurationThresholdSec = 3600 (alert if P95 duration exceeds 1 hour)
   - **Customizable:** Adjust these values to match your SLAs

#### 4. **Report Sheet (Executive Summary)**
   - **Key Performance Indicators:**
     - Total Jobs (last 30 days)
     - Total Successes
     - Total Failures
     - Overall Success Rate
     - Max Daily Jobs
     - Average Duration (seconds)
     - P95 Duration (seconds)
   - **Visualizations:**
     - **Line Chart:** Daily Pipeline Runs (Last 30 Days)
       - Shows trend of total job executions over time
     - **Column Chart:** Success vs Failure by Day
       - Stacked view of successful and failed jobs
   - **Print-Ready:**
     - Print area configured (A1:Z60)
     - Fit-to-width enabled for easy PDF export

#### 5. **README Sheet**
   - User guide with instructions on:
     - How to update data
     - How to adjust thresholds
     - How to export to PDF/CSV/HTML
     - Formula explanations

### Key Features

‚úÖ **Auto-Calculating Formulas**
   - All metrics recalculate when Data sheet is updated
   - Structured references ensure formulas don't break

‚úÖ **Dynamic Charts**
   - Charts automatically update with new data
   - Professional styling for presentations

‚úÖ **Conditional Formatting**
   - Visual alerts based on configurable thresholds
   - Easy identification of problem areas

‚úÖ **Executive-Friendly**
   - Clear KPIs and visualizations
   - Print-ready format
   - Professional appearance

## üîß Integration with Databricks

### Current Implementation

The solution currently uses **sample data** for demonstration. To integrate with actual Databricks job data:

1. **Modify the `generate_sample_data()` function** in `generate_pipeline_report.py`
2. **Replace with Databricks API calls:**

```python
import requests
from datetime import datetime, timedelta

def fetch_databricks_job_data(databricks_instance, databricks_token, job_names, days=30):
    """
    Fetch actual job execution data from Databricks API
    """
    headers = {'Authorization': f'Bearer {databricks_token}'}
    base_url = f'{databricks_instance}/api/2.1/jobs'
    
    data = []
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    for job_name in job_names:
        # Get job ID
        response = requests.get(f'{base_url}/list', headers=headers)
        jobs = response.json().get('jobs', [])
        job = next((j for j in jobs if j['settings']['name'] == job_name), None)
        
        if not job:
            continue
            
        job_id = job['job_id']
        
        # Get job runs
        runs_response = requests.get(
            f'{base_url}/runs/list',
            headers=headers,
            params={'job_id': job_id, 'limit': 1000}
        )
        
        runs = runs_response.json().get('runs', [])
        
        for run in runs:
            run_start = datetime.fromtimestamp(run['start_time'] / 1000)
            
            if run_start < start_date:
                continue
                
            run_end = datetime.fromtimestamp(run['end_time'] / 1000) if run.get('end_time') else datetime.now()
            duration = (run_end - run_start).total_seconds()
            
            status = 'Success' if run['state']['life_cycle_state'] == 'TERMINATED' and run['state'].get('result_state') == 'SUCCESS' else 'Failed'
            error_code = run['state'].get('state_message', '') if status == 'Failed' else ''
            
            data.append({
                'Date': run_start.date(),
                'PipelineID': f'PL{job_id}',
                'PipelineName': job_name,
                'Owner': job.get('creator_user_name', 'Unknown'),
                'System': 'Databricks',
                'JobType': 'ETL',
                'Status': status,
                'DurationSec': int(duration),
                'StartTime': run_start,
                'EndTime': run_end,
                'ErrorCode': error_code
            })
    
    return pd.DataFrame(data)
```

3. **Update the `create_workbook()` function:**

```python
def create_workbook(databricks_instance, databricks_token, job_names):
    # Replace sample data with actual Databricks data
    df_data = fetch_databricks_job_data(databricks_instance, databricks_token, job_names)
    # Rest of the function remains the same
```

## üìÅ Files in This Repository

1. **Databricks_Monitoring_Report.txt**
   - Real-time monitoring results from Databricks
   - Root cause analysis for failed jobs
   - Failure pattern detection

2. **generate_pipeline_report.py**
   - Python script to generate Excel workbook
   - Contains all logic for data processing, formatting, and chart creation
   - Easily customizable for your needs

3. **README.md**
   - This file - comprehensive documentation

## üöÄ Quick Start

### Step 1: Monitor Databricks Jobs

Use the Databricks monitoring tool with your credentials to monitor jobs and generate reports.

### Step 2: Generate Excel Report

```bash
python generate_pipeline_report.py
```

### Step 3: Review Results

1. Open `Pipeline_30Day_Trend_Report.xlsx`
2. Check the **Report** sheet for executive summary
3. Review **Metrics** for daily trends
4. Examine **Data** for detailed job execution records
5. Adjust **Config** thresholds as needed

## üìà Sample Insights

Based on the monitoring data:

- **Job1 has a 100% failure rate** over the last 5 runs
- **Infrastructure issues detected** - likely memory, cluster, or timeout problems
- **Immediate action required** to resolve systemic failure

## üîí Security Notes

- **Never commit tokens or credentials to GitHub**
- Use environment variables or secure vaults for sensitive data
- Rotate tokens regularly
- Use read-only tokens when possible

## üìû Support

For questions or issues:
- Review the README sheet in the Excel workbook
- Check Databricks UI for detailed logs
- Contact the Data Engineering team

## üìù License

This solution is provided as-is for internal use.

---

**Generated:** 2026-02-14  
**Version:** 1.0  
**Status:** Production Ready